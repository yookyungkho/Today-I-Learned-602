# [210216 TIL] Lecun DL Course) Lecture 10. Self-Supervised Learning

Today I Learned

_written by 602_

<br/>



---

뉴욕대학교 Lecun 교수의 Deep Learning Course,

2020년 강의영상으로 최신 트렌드도 반영한 강의라는 점에서 유용한 코스다.

이번 주차 딥러닝 스터디에서는 10강 Self-Supervised Learning을 다루었다.

처음 접하는 내용이 대부분이라 꽤나 어려웠다🤦‍♀️



<br/>



---

# 👀 Lecun DL Course) Lecture 10. Self-Supervised Learning





## Main Idea

세상의 대부분 이미지는 label이 없다.

**Obtain labels using "semi-automatic" process instead**



cf) SSL in NLP

- Bert에서의 Masking

<br/>



## Pretext task



### 1. Context Autoencoders

- Fill in the blanks of image(이미지 빈칸 예측)

### 2. RotNet

- 이미지를 각 각도로 로테이션한 데이터를 가지고 이미지의 회전 각도를 예측하는 task

### 3. JigSAW

- 이미지를 n등분해서 셔플한 후, 퍼즐맞추기처럼 이미지의 순서 예측

### 4. Evaluation

- pre-train을 가지고 target task에서 fine-tuning한 성능 평가



<br/>



---



### 2018년 이후의 물음

1. pretext task 성능을 높이는 것 말고 내 목적에 맞는 **Invariant mapping**이 중요한 것 아닌가!
   - represantation should be stable for slightly transformed version of image
2. 비슷한 이미지는 **공간상의 비슷한 위치**에 모여있어야 한다
   - semantically related images should be aligned together



---



<br/>



## Contrastive Learning



### Idea Flow

- 비슷한 속성(색)의 이미지들은 embedding된 space내에서의 distance가 더 짧을 것이다

  - similarity를 이용한 loss function -> distance의 exponential을 softmax 연산을 통해 cross entropy 걸어줌

  - label이 없는데 이미지들이 관련있다라는걸 어떻게 정의하나?

    - Data Augmentation을 통해 해결하자!

      - 이미지를 잘라서 여러개의 이미지로 만들기 -> 두 이미지는 동일한 이미지에서 왔기 때문에 related(positive)일 것이다
      - 서로 다른 이미지들은 임베딩된 공간 내에서 최대한 멀리 위치하도록(negative)

      

### Problem

일반적인 지도학습 과정은 target이 정해져있고 input이 target에 가까워지도록학습이 되는것이고 SSL은 비슷한 두 타겟이 가까워지도록 학습이되는 것인데 target들이 움직이는 문제 발생

즉, 타겟이 고정되지 않음



### Solution

1. **SimCLR** - Google의 아이디어 (ICML 2020)

   - Using a lot of negative samples

   - batch size를 미친듯이 늘리자(16384 ...)
     - 공간 내 데이터들이 빽빽하게 위치해있어서 크게 움직이지 않고 stable하게 조정됨

2. **MoCo** - Momentum Encoder

   - augment된 이미지가 통과하는 네트워크를 업데이트하지 않고 다른 target만 움직이도록
   - encoder가 momentum 방식으로 서서히 학습되는, 복사되는 네트워크 사용
   - Encoder와 비슷하면서 움직임의 변동폭을 최소한으로 줄이는 방식

   

- 지도학습보다 Fine-tuning 성능이 더 높더라!

<br/>



### 추가 Point

- 서로 다른 친구들을 밀지 말고 같은 친구들끼리 당기기만 하자
  - 이렇게 했을 때 문제점: 한 점으로 다 모이게 되면 loss는 적게 수렴 but 바람직하지 않다
  - 따라서 최신 논문들은 **당기되, 한점으로 모이지는 않도록 하는 방법**을 다루고 있음
- ICLR 2020에 여러 방법론들 등장
- 애초에 그럼 Contrastive Learning이 올바른 방식인가? -> Generative가 더 적합하지 않을까?
- 강화학습에서의 적용(데이터 구하기는 어렵지만 유망한 분야)



---

