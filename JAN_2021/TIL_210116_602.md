# [210116 TIL] Today I Learned

_written by 602_

<br/>



---

컨퍼런스 D-day



### 1. Tacotron과 Transformers, 그리고 Masking

- tacotron: 동작을 명확히 구현하지만, 값이 튀는 현상이 발생
- transforemrs: 안정적인 양상을 보이지만, 세밀한 동작을 잘 따라가지는 못함
- 제로 패딩의 영향을 무력화시키기 위한 장치로 Masking layer를 추가하였으나, Decoder prenet의 GRU 층에서 차원이 바뀌어 0값이 이후 연산에 추가 -> attention 구조를 아예 바꾸어 0의 영향을 받지 않도록 조치해야함

<br/>



### 2. Json 파일 생성 및 로드

```python
import json

## json 파일 생성
with open("./text2keypoint/result_real.json", 'w', encoding='utf-8') as make_file: 
    json.dump(ref2.tolist(), make_file, indent="\t") #구분자: tab
    
## json 파일 로드
file_path = "/content/drive/My Drive/DwNet/NIA_SL_SEN0151_REAL10_F_morpheme.json"
with open(file_path, "r", encoding="UTF8") as json_file:
    json_data = json.load(json_file)
    print(json.dumps(json_data, indent=4)) #깔끔하게 출력해주는 코드
```

이번 컨퍼런스를 준비하면서 유용한 코드들, 그러나 자주 까먹는 코드들을 다시 한 번 정리할 수 있어서 좋았다. 딕셔너리형 데이터를 저장해둘 때 특히나 더 유용한 json!

<br/>



### 3. Colab에서는 Argparse 대신 Easydict

```python
import easydict

opt = easydict.EasyDict({ "name": "label2city", "checkpoints_dir": "checkpoints", "norm": "instance",
        "use_dropout": "store_true", "data_type":32, "verbose": False, "naive_warp": False, "grid_padding": 'reflection',
        "no_coarse_warp": False, "no_refining_warp": False, "prev_frame_num": 2, "batchSize": 1, "loadSize":256,
        "input_nc":3, "output_nc":3, "dataroot":'datasets/fashion_test', "source_num":10, "resize_or_crop":'resize',
        "serial_batches":'store_true', "no_flip":'store_true', "nThreads":2, "max_dataset_size":float("inf"),
        "display_winsize":512, "tf_log":'store_true', "ngf":64, "n_downsample_global":2, "n_blocks_global":9,
        "n_blocks_local":3, "niter_fix_global":0})

opt["display_freq"]=100
```

깃헙에서 클론한 모델 학습 코드를 코랩에서 실행하면 대부분 argparse 파트에서 오류가 뜨곤 하는데 주피터노트북과 같은 대화형 콘솔에서는 argparse가 실해이 되지 않는다. 따라서, 코랩으로 딥러닝 모델을 학습시킬 때에는,  argparse 대신 Easydict를 이용하여 미리 하이퍼파라미터 등 초기 모델 설정을 할 수 있다.  또 다른 방법으로 `yaml`파일 형식이 있는데 이건 내일 정리할 예정이다.

